{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7b4ab6",
   "metadata": {},
   "source": [
    "# In This Project we are Scrapping Data i.e Name(author), Quotes and Tags\n",
    "# Site Used: http://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0dfaa",
   "metadata": {},
   "source": [
    "# Libraries Used:\n",
    " Pandas: Here pandas is used to to create dataframe and save it to csv file.\n",
    " \n",
    " BeautifulSoup: Here BeautifulSoup is used  to scrape all required information from webpages.\n",
    " \n",
    " Requests: Here Requests is used to send http requests and get all response data from website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a82088",
   "metadata": {},
   "source": [
    "# Installing All Important Libraries Which Is Required For This Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8862ab1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0140f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4->bs4) (2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing BeautifulSoup\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f627419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankur\\appdata\\roaming\\python\\python311\\site-packages (from requests) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing requests\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c60c3",
   "metadata": {},
   "source": [
    "# Importing All Important Libraries Which Is Required For This Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9fabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d94b63",
   "metadata": {},
   "source": [
    "# Create functions for the end-to-end process of downloading, parsing, and saving CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2da8a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of page with required data is: 10\n",
      "Data saved in csv file\n"
     ]
    }
   ],
   "source": [
    "# This is a Function used to scrap data from websites, in this project we are sacrapping name(author), quotes and tags.\n",
    "def scrap_data(): \n",
    "# creating empty list here for storing our scrapped data.\n",
    "    Content = []\n",
    "# Here i = 1 means that we are starting our scrapping data process from page 1.\n",
    "    i = 1\n",
    "\n",
    "    '''\n",
    "    Using while loop here to check all the available pages which has information which we require i.e name, quotes and tags.\n",
    "    Using this here because we don't know the number of pages available, to get rid of manually checking all the pages we are\n",
    "    using while loop here which will do all the work for us automatically.\n",
    "    '''\n",
    "    while True:\n",
    "        url = f\"http://quotes.toscrape.com/page/{i}/\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        Data = soup.find_all('div', class_='quote')\n",
    "        if not Data:\n",
    "            #if no data is found it will save our data in csv file.\n",
    "            print(\"Total number of page with required data is:\", i-1)\n",
    "            save_as_csv(Content)\n",
    "            print(\"Data saved in csv file\")\n",
    "            break # stop requesting pages if no quotes are found\n",
    "\n",
    "        '''\n",
    "        Using for loop to iterate through all the quote elements on the page and extracts the name of the author, the quote text, \n",
    "        and the tags associated with the quote.\n",
    "        '''\n",
    "        for data in Data:\n",
    "            # To Scrap Name(author)\n",
    "            name = data.find('small', class_='author').text\n",
    "            # To Scrap Quotes\n",
    "            quotes = data.find('span', class_='text').text\n",
    "            # To Scrap tags\n",
    "            tag = data.find('div', class_='tags')\n",
    "            keywords = tag.find('meta', attrs={'itemprop': 'keywords'})\n",
    "            tags = keywords['content']\n",
    "            #here appending all extracted data to empty list which is mentioned above i.e. Content = [].\n",
    "            Content.append([name, quotes, tags])\n",
    "        i += 1 #increment that page by 1\n",
    "        \n",
    "# This Function is for saving our scraped data in csv format.\n",
    "def save_as_csv(Content):\n",
    "    data = pd.DataFrame(Content, columns = ['Name', \"Quotes\", \"Tags\"])\n",
    "    data.to_csv('quote_Scrap.csv', index = False)\n",
    "        \n",
    "#Here calling scrap_data() function to execute this function    \n",
    "scrap_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a45b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>change,deep-thoughts,thinking,world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>abilities,choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>inspirational,life,live,miracle,miracles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>aliteracy,books,classic,humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>be-yourself,inspirational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>better-life-empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Madeleine L'Engle</td>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>books,children,difficult,grown-ups,write,write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>“A person's a person, no matter how small.”</td>\n",
       "      <td>inspirational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>books,mind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                             Quotes   \n",
       "0      Albert Einstein  “The world as we have created it is a process ...  \\\n",
       "1         J.K. Rowling  “It is our choices, Harry, that show what we t...   \n",
       "2      Albert Einstein  “There are only two ways to live your life. On...   \n",
       "3          Jane Austen  “The person, be it gentleman or lady, who has ...   \n",
       "4       Marilyn Monroe  “Imperfection is beauty, madness is genius and...   \n",
       "..                 ...                                                ...   \n",
       "95          Harper Lee  “You never really understand a person until yo...   \n",
       "96   Madeleine L'Engle  “You have to write the book that wants to be w...   \n",
       "97          Mark Twain  “Never tell the truth to people who are not wo...   \n",
       "98           Dr. Seuss        “A person's a person, no matter how small.”   \n",
       "99  George R.R. Martin  “... a mind needs books as a sword needs a whe...   \n",
       "\n",
       "                                                 Tags  \n",
       "0                 change,deep-thoughts,thinking,world  \n",
       "1                                   abilities,choices  \n",
       "2            inspirational,life,live,miracle,miracles  \n",
       "3                       aliteracy,books,classic,humor  \n",
       "4                           be-yourself,inspirational  \n",
       "..                                                ...  \n",
       "95                                better-life-empathy  \n",
       "96  books,children,difficult,grown-ups,write,write...  \n",
       "97                                              truth  \n",
       "98                                      inspirational  \n",
       "99                                         books,mind  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the information in the saved CSV files by reading them back using Pandas.\n",
    "\n",
    "df = pd.read_csv(\"quote_Scrap.csv\")\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af4f71",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "This is a Python project that is used to scrape data from a website. The function is designed to extract the name of the author, quotes, and tags from a website called \"http://quotes.toscrape.com/\".\n",
    "\n",
    "The function scrap_data() begins by creating an empty list called \"Content\" to store the scraped data. It then sets a variable called \"i\" to 1, indicating that it will begin scraping data from page 1 of the website.\n",
    "\n",
    "The function uses a while loop to iterate through all the available pages of the website. It does this by dynamically creating a URL for each page using string interpolation and requests the HTML content of the page using the requests library. The HTML content is then parsed using the BeautifulSoup library.Also, using while loop here to check all the available pages which has information which we require i.e name, quotes and tags.Using this here because we don't know the number of pages available, to get rid of manually checking all the pages we are using while loop here which will do all the work for us automatically. If no required data is found the while loop will break.\n",
    "\n",
    "The function then uses a for loop to iterate through all the quote elements on the page and extracts the name of the author, the quote text, and the tags associated with the quote. This data is then appended to the \"Content\" list.\n",
    "\n",
    "Once all the pages have been scraped, the function calls another function called \"save_as_csv\" to save the scraped data to a CSV file.\n",
    "\n",
    "The \"save_as_csv\" function takes the \"Content\" list as an input parameter and converts it into a Pandas DataFrame. The DataFrame is then saved as a CSV file called \"quote_Scrap.csv\".\n",
    "\n",
    "Overall, this function is a useful tool for anyone who needs to scrape data from websites, especially for those who need to extract information from multiple pages of a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b99e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f5110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
